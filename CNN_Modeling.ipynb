{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6e10d9",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "There are three steps to creating this model:\n",
    "\n",
    "1. **Vectorization**\n",
    "2. **Train/Validation/Test Split**\n",
    "3. **Modeling**: We apply a baseline CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc873a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv1D, Flatten, LSTM, GRU, GlobalMaxPooling1D\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom functions\n",
    "from explore import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2f23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('processed_data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4efde39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet                       1830\n",
       "Years                          0\n",
       "Lemmatized                  3220\n",
       "Tweets with no Stopwords    6230\n",
       "Short Tweets                6893\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d725a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aad9196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018 2017 2019]\n"
     ]
    }
   ],
   "source": [
    "print(df['Years'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4f950",
   "metadata": {},
   "source": [
    "# CNN for Text Analysis\n",
    "\n",
    "Neural networks analyze texts in a slightly different way with words as opposed to the sparse TF-IDF framework. Since this is a large dataset, a CNN maybe able to pick up intricate patterns. Preprocessing with CNNs requires it to be processed with Keras' `Embedding.()` when it comes to the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef012e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweets with no Stopwords'], \n",
    "                                                    df['Years'], test_size = 0.3, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f1a7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words = 5000, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower = True, \n",
    "                  split = ' ', oov_token = True)\n",
    "token.fit_on_texts(X_train)\n",
    "X_train_seq = token.texts_to_sequences(X_train)\n",
    "X_test_seq = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0639eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "transformed = encoder.transform(y_train)\n",
    "y_train_encoded = pd.DataFrame(transformed)\n",
    "transformed_test = encoder.transform(y_test)\n",
    "y_test_encoded = pd.DataFrame(transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61ca7323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length(X_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ec1bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d04dd755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374556"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of words in the corpus\n",
    "vocabulary_size = len(token.word_index)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "042aa50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d599b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq_pad = pad_sequences(X_train_seq, maxlen = max_length, padding = 'post')\n",
    "X_test_seq_pad = pad_sequences(X_test_seq, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d6a8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(X_train_seq_pad, y_train_encoded, \n",
    "                                                                  test_size = 0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b8f0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = models.Sequential()\n",
    "emb_model.add(layers.Embedding(number_of_words, 200, input_length = max_length))\n",
    "emb_model.add(layers.Conv1D(50, 3, activation = 'relu', input_shape = (200, 1)))\n",
    "emb_model.add(layers.GlobalMaxPooling1D())\n",
    "emb_model.add(layers.Dense(3, activation = 'softmax'))\n",
    "emb_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a11c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5582/5582 [==============================] - 234s 42ms/step - loss: 0.4772 - accuracy: 0.8313 - val_loss: 0.4219 - val_accuracy: 0.8487\n",
      "Epoch 2/10\n",
      "5582/5582 [==============================] - 235s 42ms/step - loss: 0.3918 - accuracy: 0.8549 - val_loss: 0.4318 - val_accuracy: 0.8429\n",
      "Epoch 3/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.3493 - accuracy: 0.8673 - val_loss: 0.4351 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.3002 - accuracy: 0.8863 - val_loss: 0.4724 - val_accuracy: 0.8313\n",
      "Epoch 5/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.2548 - accuracy: 0.9045 - val_loss: 0.5157 - val_accuracy: 0.8279\n",
      "Epoch 6/10\n",
      "5582/5582 [==============================] - 230s 41ms/step - loss: 0.2140 - accuracy: 0.9216 - val_loss: 0.5731 - val_accuracy: 0.8266\n",
      "Epoch 7/10\n",
      "5582/5582 [==============================] - 234s 42ms/step - loss: 0.1803 - accuracy: 0.9344 - val_loss: 0.6371 - val_accuracy: 0.8215\n",
      "Epoch 8/10\n",
      "5582/5582 [==============================] - 236s 42ms/step - loss: 0.1557 - accuracy: 0.9440 - val_loss: 0.7100 - val_accuracy: 0.7982\n",
      "Epoch 9/10\n",
      "5582/5582 [==============================] - 238s 43ms/step - loss: 0.1370 - accuracy: 0.9513 - val_loss: 0.7741 - val_accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "5582/5582 [==============================] - 239s 43ms/step - loss: 0.1200 - accuracy: 0.9569 - val_loss: 0.8477 - val_accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "emb_model_history = emb_model.fit(X_train_emb, y_train_emb, epochs = 10, batch_size = 64, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c48189ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834/6834 [==============================] - 35s 5ms/step - loss: 0.8500 - accuracy: 0.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8499530553817749, 0.8045334219932556]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_val_emb, y_val_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "099350b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b369b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/9763 [===>..........................] - ETA: 42s - loss: 0.8522 - accuracy: 0.8059"
     ]
    }
   ],
   "source": [
    "emb_model.evaluate(X_test_seq_pad, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb9e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
