{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d877b3a",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "There are three steps to creating this model:\n",
    "\n",
    "1. **Vectorization**\n",
    "2. **Train/Validation/Test Split**\n",
    "3. **Modeling**: We apply a baseline CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a4b7447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Conv1D, LSTM, GlobalMaxPooling1D, InputLayer, Dropout, SpatialDropout1D, Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom functions\n",
    "from explore import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683e1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('processed_data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fdd27ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet                       1830\n",
       "Years                          0\n",
       "Lemmatized                  3220\n",
       "Tweets with no Stopwords    6230\n",
       "Short Tweets                6893\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953761fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8352436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018 2017 2019]\n"
     ]
    }
   ],
   "source": [
    "print(df['Years'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ea211",
   "metadata": {},
   "source": [
    "# CNN for Text Analysis\n",
    "\n",
    "Neural networks analyze texts in a slightly different way with words as opposed to the sparse TF-IDF framework. Since this is a large dataset, a CNN maybe able to pick up intricate patterns. Preprocessing with CNNs requires it to be processed with Keras' `Embedding.()` when it comes to the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca931099",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweets with no Stopwords'], \n",
    "                                                    df['Years'], test_size = 0.3, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a725eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words = 5000, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower = True, \n",
    "                  split = ' ', oov_token = True)\n",
    "token.fit_on_texts(X_train)\n",
    "X_train_seq = token.texts_to_sequences(X_train)\n",
    "X_test_seq = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e586a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "transformed = encoder.transform(y_train)\n",
    "y_train_encoded = pd.DataFrame(transformed)\n",
    "transformed_test = encoder.transform(y_test)\n",
    "y_test_encoded = pd.DataFrame(transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96452168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length(X_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d10885ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c54b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374556"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of words in the corpus\n",
    "vocabulary_size = len(token.word_index)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a18ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bdfdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq_pad = pad_sequences(X_train_seq, maxlen = max_length, padding = 'post')\n",
    "X_test_seq_pad = pad_sequences(X_test_seq, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0933081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(X_train_seq_pad, y_train_encoded, \n",
    "                                                                  test_size = 0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c24d3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = models.Sequential()\n",
    "emb_model.add(layers.Embedding(number_of_words, 200, input_length = max_length))\n",
    "emb_model.add(layers.Conv1D(50, 3, activation = 'relu', input_shape = (200, 1)))\n",
    "emb_model.add(layers.GlobalMaxPooling1D())\n",
    "emb_model.add(layers.Dense(3, activation = 'softmax'))\n",
    "emb_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f35b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5582/5582 [==============================] - 234s 42ms/step - loss: 0.4772 - accuracy: 0.8313 - val_loss: 0.4219 - val_accuracy: 0.8487\n",
      "Epoch 2/10\n",
      "5582/5582 [==============================] - 235s 42ms/step - loss: 0.3918 - accuracy: 0.8549 - val_loss: 0.4318 - val_accuracy: 0.8429\n",
      "Epoch 3/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.3493 - accuracy: 0.8673 - val_loss: 0.4351 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.3002 - accuracy: 0.8863 - val_loss: 0.4724 - val_accuracy: 0.8313\n",
      "Epoch 5/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.2548 - accuracy: 0.9045 - val_loss: 0.5157 - val_accuracy: 0.8279\n",
      "Epoch 6/10\n",
      "5582/5582 [==============================] - 230s 41ms/step - loss: 0.2140 - accuracy: 0.9216 - val_loss: 0.5731 - val_accuracy: 0.8266\n",
      "Epoch 7/10\n",
      "5582/5582 [==============================] - 234s 42ms/step - loss: 0.1803 - accuracy: 0.9344 - val_loss: 0.6371 - val_accuracy: 0.8215\n",
      "Epoch 8/10\n",
      "5582/5582 [==============================] - 236s 42ms/step - loss: 0.1557 - accuracy: 0.9440 - val_loss: 0.7100 - val_accuracy: 0.7982\n",
      "Epoch 9/10\n",
      "5582/5582 [==============================] - 238s 43ms/step - loss: 0.1370 - accuracy: 0.9513 - val_loss: 0.7741 - val_accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "5582/5582 [==============================] - 239s 43ms/step - loss: 0.1200 - accuracy: 0.9569 - val_loss: 0.8477 - val_accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "emb_model_history = emb_model.fit(X_train_emb, y_train_emb, epochs = 10, batch_size = 64, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd3a1124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834/6834 [==============================] - 35s 5ms/step - loss: 0.8500 - accuracy: 0.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8499530553817749, 0.8045334219932556]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_val_emb, y_val_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1084dda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9763/9763 [==============================] - 50s 5ms/step - loss: 0.8505 - accuracy: 0.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8504638075828552, 0.8045485019683838]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_test_seq_pad, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b023f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4882/4882 [==============================] - 39s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2017       0.86      0.90      0.88     85882\n",
      "        2018       0.84      0.85      0.84    191654\n",
      "        2019       0.39      0.34      0.36     34874\n",
      "\n",
      "    accuracy                           0.80    312410\n",
      "   macro avg       0.70      0.69      0.70    312410\n",
      "weighted avg       0.80      0.80      0.80    312410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get classification report\n",
    "y_pred = emb_model.predict(X_test_seq_pad, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = encoder.inverse_transform(y_pred) # Undo one-hot encoding\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1f233be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 83, 200)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 81, 50)            30050     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,030,203\n",
      "Trainable params: 1,030,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c663e",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91c9a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fast_text():\n",
    "    fast_text = Sequential()\n",
    "    fast_text.add(InputLayer((max_length,)))\n",
    "    fast_text.add(Embedding(input_dim = vocabulary_size + 1, output_dim = 3, trainable = True))\n",
    "    fast_text.add(SpatialDropout1D(0.5))\n",
    "    fast_text.add(GlobalMaxPooling1D())\n",
    "    fast_text.add(Dropout(0.5))\n",
    "    fast_text.add(Dense(3, activation = 'softmax'))\n",
    "    return fast_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e1b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10751/11163 [===========================>..] - ETA: 7s - loss: 0.7227 - accuracy: 0.7083"
     ]
    }
   ],
   "source": [
    "fast_text.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "fast_text.fit(X_train_emb, y_train_emb, epochs = 10, verbose = 1, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb16d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification report\n",
    "y_pred = fast_text.predict(X_test_seq_pad, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = encoder.inverse_transform(y_pred) # Undo one-hot encoding\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6119906",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc20da",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_lstm_model():\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(InputLayer((max_length,)))\n",
    "    model_lstm.add(SpatialDropout1D(0.5))\n",
    "    model_lstm.add(BatchNormalization())\n",
    "    model_lstm.add(Bidirectional(LSTM(125)))\n",
    "    model_lstm.add(BatchNormalization())\n",
    "    model_lstm.add(Dropout(0.5))\n",
    "    model_lstm.add(Dense(3, activation = 'softmax'))\n",
    "    return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b254241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(loss = 'categorical_crossentropy', optimzer = 'adam', metrics = ['accuracy'])\n",
    "model_lstm.fit(X_train_emb, y_train_emb, validation_data = (X_val_emb, y_val_emb), epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b972da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification report\n",
    "y_pred = model_lstm.predict(X_test_seq_pad, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = encoder.inverse_transform(y_pred) # Undo one-hot encoding\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
