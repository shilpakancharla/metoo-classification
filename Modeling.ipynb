{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f705853",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "There are three steps to creating this model:\n",
    "\n",
    "1. **Vectorization**\n",
    "2. **Train/Validation/Test Split**\n",
    "3. **Modeling**: We apply a baseline CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43644bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Conv1D, LSTM, GlobalMaxPooling1D, InputLayer, Dropout, SpatialDropout1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom functions\n",
    "from explore import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f0aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('processed_data/clean_data.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ec7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweets with no Stopwords'], \n",
    "                                                    df['Years'], test_size = 0.3, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3fe9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words = 5000, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower = True, \n",
    "                  split = ' ', oov_token = True)\n",
    "token.fit_on_texts(X_train)\n",
    "X_train_seq = token.texts_to_sequences(X_train)\n",
    "X_test_seq = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7353a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "transformed = encoder.transform(y_train)\n",
    "y_train_encoded = pd.DataFrame(transformed)\n",
    "transformed_test = encoder.transform(y_test)\n",
    "y_test_encoded = pd.DataFrame(transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59878887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max_seq_length(X_train_seq)\n",
    "# Total number of words in the corpus\n",
    "vocabulary_size = len(token.word_index)\n",
    "number_of_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f28b307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq_pad = pad_sequences(X_train_seq, maxlen = max_length, padding = 'post')\n",
    "X_test_seq_pad = pad_sequences(X_test_seq, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4fddb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(X_train_seq_pad, y_train_encoded, \n",
    "                                                                  test_size = 0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180547c8",
   "metadata": {},
   "source": [
    "# CNN for Text Analysis\n",
    "\n",
    "Neural networks analyze texts in a slightly different way with words as opposed to the sparse TF-IDF framework. Since this is a large dataset, a CNN maybe able to pick up intricate patterns. Preprocessing with CNNs requires it to be processed with Keras' `Embedding.()` when it comes to the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "277a1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_CNN_model():\n",
    "    emb_model = models.Sequential()\n",
    "    emb_model.add(layers.Embedding(number_of_words, 200, input_length = max_length))\n",
    "    emb_model.add(layers.Conv1D(50, 3, activation = 'relu', input_shape = (200, 1)))\n",
    "    emb_model.add(layers.GlobalMaxPooling1D())\n",
    "    emb_model.add(layers.Dense(3, activation = 'softmax'))\n",
    "    emb_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', \n",
    "                      metrics = ['accuracy', f1, precision_measure, recall_measure])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "766a1a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5582/5582 [==============================] - 234s 42ms/step - loss: 0.4772 - accuracy: 0.8313 - val_loss: 0.4219 - val_accuracy: 0.8487\n",
      "Epoch 2/10\n",
      "5582/5582 [==============================] - 235s 42ms/step - loss: 0.3918 - accuracy: 0.8549 - val_loss: 0.4318 - val_accuracy: 0.8429\n",
      "Epoch 3/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.3493 - accuracy: 0.8673 - val_loss: 0.4351 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.3002 - accuracy: 0.8863 - val_loss: 0.4724 - val_accuracy: 0.8313\n",
      "Epoch 5/10\n",
      "5582/5582 [==============================] - 233s 42ms/step - loss: 0.2548 - accuracy: 0.9045 - val_loss: 0.5157 - val_accuracy: 0.8279\n",
      "Epoch 6/10\n",
      "5582/5582 [==============================] - 230s 41ms/step - loss: 0.2140 - accuracy: 0.9216 - val_loss: 0.5731 - val_accuracy: 0.8266\n",
      "Epoch 7/10\n",
      "5582/5582 [==============================] - 234s 42ms/step - loss: 0.1803 - accuracy: 0.9344 - val_loss: 0.6371 - val_accuracy: 0.8215\n",
      "Epoch 8/10\n",
      "5582/5582 [==============================] - 236s 42ms/step - loss: 0.1557 - accuracy: 0.9440 - val_loss: 0.7100 - val_accuracy: 0.7982\n",
      "Epoch 9/10\n",
      "5582/5582 [==============================] - 238s 43ms/step - loss: 0.1370 - accuracy: 0.9513 - val_loss: 0.7741 - val_accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "5582/5582 [==============================] - 239s 43ms/step - loss: 0.1200 - accuracy: 0.9569 - val_loss: 0.8477 - val_accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "cnn_model = define_CNN_model()\n",
    "cnn_model.summary()\n",
    "cnn_model_history = cnn_model.fit(X_train_emb, y_train_emb, epochs = 10, batch_size = 64, \n",
    "                                  validation_data = (X_val_emb, y_val_emb), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ffb0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834/6834 [==============================] - 35s 5ms/step - loss: 0.8500 - accuracy: 0.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8499530553817749, 0.8045334219932556]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_history(emb_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8003a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4882/4882 [==============================] - 39s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2017       0.86      0.90      0.88     85882\n",
      "        2018       0.84      0.85      0.84    191654\n",
      "        2019       0.39      0.34      0.36     34874\n",
      "\n",
      "    accuracy                           0.80    312410\n",
      "   macro avg       0.70      0.69      0.70    312410\n",
      "weighted avg       0.80      0.80      0.80    312410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get classification report\n",
    "y_pred = cnn_model.predict(X_test_seq_pad, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = encoder.inverse_transform(y_pred) # Undo one-hot encoding\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3edb8c8",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa77d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fast_text():\n",
    "    fast_text = Sequential()\n",
    "    fast_text.add(InputLayer((max_length,)))\n",
    "    fast_text.add(Embedding(input_dim = vocabulary_size + 1, output_dim = 3, trainable = True))\n",
    "    fast_text.add(SpatialDropout1D(0.5))\n",
    "    fast_text.add(GlobalMaxPooling1D())\n",
    "    fast_text.add(Dropout(0.5))\n",
    "    fast_text.add(Dense(3, activation = 'softmax'))\n",
    "    fast_text.compile(loss = 'categorical_crossentropy', optimizer = 'adam', \n",
    "                      metrics = ['accuracy', f1, precision_measure, recall_measure])\n",
    "    return fast_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd38e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11163/11163 [==============================] - 223s 20ms/step - loss: 0.7227 - accuracy: 0.7083 - val_loss: 0.5698 - val_accuracy: 0.8287\n",
      "Epoch 2/10\n",
      "11163/11163 [==============================] - 212s 19ms/step - loss: 0.7201 - accuracy: 0.7094 - val_loss: 0.5683 - val_accuracy: 0.8295\n",
      "Epoch 3/10\n",
      "11163/11163 [==============================] - 203s 18ms/step - loss: 0.7226 - accuracy: 0.7085 - val_loss: 0.5727 - val_accuracy: 0.8292\n",
      "Epoch 4/10\n",
      "11163/11163 [==============================] - 202s 18ms/step - loss: 0.7211 - accuracy: 0.7091 - val_loss: 0.5789 - val_accuracy: 0.8203\n",
      "Epoch 5/10\n",
      "11163/11163 [==============================] - 193s 17ms/step - loss: 0.7193 - accuracy: 0.7104 - val_loss: 0.5721 - val_accuracy: 0.8265\n",
      "Epoch 6/10\n",
      "11163/11163 [==============================] - 213s 19ms/step - loss: 0.7189 - accuracy: 0.7107 - val_loss: 0.5732 - val_accuracy: 0.8258\n",
      "Epoch 7/10\n",
      "11163/11163 [==============================] - 240s 22ms/step - loss: 0.7193 - accuracy: 0.7106 - val_loss: 0.5783 - val_accuracy: 0.8202\n",
      "Epoch 8/10\n",
      "11163/11163 [==============================] - 206s 18ms/step - loss: 0.7226 - accuracy: 0.7091 - val_loss: 0.5784 - val_accuracy: 0.8245\n",
      "Epoch 9/10\n",
      "11163/11163 [==============================] - 205s 18ms/step - loss: 0.7205 - accuracy: 0.7095 - val_loss: 0.5757 - val_accuracy: 0.8233\n",
      "Epoch 10/10\n",
      "11163/11163 [==============================] - 194s 17ms/step - loss: 0.7199 - accuracy: 0.7092 - val_loss: 0.5782 - val_accuracy: 0.8203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9a4a65d08>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text = make_fast_text()\n",
    "fast_text.summary()\n",
    "fast_text_history = fast_text.fit(X_train_emb, y_train_emb, epochs = 10, batch_size = 64, \n",
    "                                  validation_data = (X_val_emb, y_val_emb), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65427b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4882/4882 [==============================] - 5s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2017       0.85      0.89      0.87     85882\n",
      "        2018       0.81      0.94      0.87    191654\n",
      "        2019       0.00      0.00      0.00     34874\n",
      "\n",
      "    accuracy                           0.82    312410\n",
      "   macro avg       0.55      0.61      0.58    312410\n",
      "weighted avg       0.73      0.82      0.77    312410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get classification report\n",
    "y_pred = fast_text.predict(X_test_seq_pad, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = encoder.inverse_transform(y_pred) # Undo one-hot encoding\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a8f2",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52bccfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_LSTM_model():\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(InputLayer((max_length,)))\n",
    "    lstm_model.add(Embedding(input_dim = vocabulary_size + 1, output_dim = 3, trainable = True))\n",
    "    lstm_model.add(LSTM(125))\n",
    "    lstm_model.add(Dropout(0.5))\n",
    "    lstm_model.add(Dense(3, activation = 'softmax'))\n",
    "    lstm_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', \n",
    "                       metrics = ['accuracy', f1, precision_measure, recall_measure])\n",
    "    return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "109464f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15946/15946 [==============================] - 1465s 92ms/step - loss: 0.9030 - accuracy: 0.6139 - val_loss: 0.9000 - val_accuracy: 0.6139\n",
      "Epoch 2/10\n",
      "15946/15946 [==============================] - 1384s 87ms/step - loss: 0.9007 - accuracy: 0.6125 - val_loss: 0.8997 - val_accuracy: 0.6139\n",
      "Epoch 3/10\n",
      "15946/15946 [==============================] - 1388s 87ms/step - loss: 0.9010 - accuracy: 0.6121 - val_loss: 0.8997 - val_accuracy: 0.6139\n",
      "Epoch 4/10\n",
      "15946/15946 [==============================] - 1391s 87ms/step - loss: 0.8991 - accuracy: 0.6136 - val_loss: 0.8997 - val_accuracy: 0.6139\n",
      "Epoch 5/10\n",
      "15946/15946 [==============================] - 1394s 87ms/step - loss: 0.9000 - accuracy: 0.6136 - val_loss: 0.8996 - val_accuracy: 0.6139\n",
      "Epoch 6/10\n",
      "15946/15946 [==============================] - 1395s 88ms/step - loss: 0.9004 - accuracy: 0.6123 - val_loss: 0.8996 - val_accuracy: 0.6139\n",
      "Epoch 7/10\n",
      "15946/15946 [==============================] - 1395s 87ms/step - loss: 0.8984 - accuracy: 0.6143 - val_loss: 0.8996 - val_accuracy: 0.6139\n",
      "Epoch 8/10\n",
      "15946/15946 [==============================] - 1400s 88ms/step - loss: 0.8995 - accuracy: 0.6129 - val_loss: 0.8996 - val_accuracy: 0.6139\n",
      "Epoch 9/10\n",
      "15946/15946 [==============================] - 1405s 88ms/step - loss: 0.8999 - accuracy: 0.6132 - val_loss: 0.8997 - val_accuracy: 0.6139\n",
      "Epoch 10/10\n",
      "15946/15946 [==============================] - 1403s 88ms/step - loss: 0.8991 - accuracy: 0.6140 - val_loss: 0.8998 - val_accuracy: 0.6139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b997087708>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = define_LSTM_model()\n",
    "lstm_model.summar\n",
    "lstm_model.fit(X_train_emb, y_train_emb, validation_data = (X_val_emb, y_val_emb), epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "566c9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4882/4882 [==============================] - 166s 34ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2017       0.00      0.00      0.00     85882\n",
      "        2018       0.61      1.00      0.76    191654\n",
      "        2019       1.00      0.00      0.00     34874\n",
      "\n",
      "    accuracy                           0.61    312410\n",
      "   macro avg       0.54      0.33      0.25    312410\n",
      "weighted avg       0.49      0.61      0.47    312410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get classification report\n",
    "y_pred = model_lstm.predict(X_test_seq_pad, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = encoder.inverse_transform(y_pred) # Undo one-hot encoding\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6c43167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 83, 3)             1123671   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 125)               64500     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 378       \n",
      "=================================================================\n",
      "Total params: 1,188,549\n",
      "Trainable params: 1,188,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
