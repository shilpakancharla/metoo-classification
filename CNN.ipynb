{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "speaking-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# reading the data as pandas dataframe\n",
    "train = pd.read_csv(\"processed_data/clean_data_201819.csv\")\n",
    "train[\"Target\"] = (train[\"Years\"] == 2018).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equivalent-regression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Years</th>\n",
       "      <th>Tweet Length</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Tweets with no Stopwords</th>\n",
       "      <th>Short Tweets</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big tipper  nice double entendre  awesome  so ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>281</td>\n",
       "      <td>big tipper nice double entendre awesome so ins...</td>\n",
       "      <td>big tipper nice double entendre awesome instea...</td>\n",
       "      <td>big tipper nice double entendre awesome instea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>313</td>\n",
       "      <td>should n't we be suppoing this brave boy who c...</td>\n",
       "      <td>n't suppoing brave boy come forward abuser mon...</td>\n",
       "      <td>n't suppoing brave boy come forward abuser mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smh  today s  movement is abt women no lo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>284</td>\n",
       "      <td>smh today s movement be abt woman no longer re...</td>\n",
       "      <td>smh today movement abt woman longer remain sil...</td>\n",
       "      <td>smh today movement abt woman longer remain sil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cry  march  protest  amp  advocate for equali...</td>\n",
       "      <td>2018</td>\n",
       "      <td>285</td>\n",
       "      <td>cry march protest amp advocate for equality be...</td>\n",
       "      <td>cry march protest amp advocate equality litera...</td>\n",
       "      <td>cry march protest amp advocate equality litera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>if    it staed with what a...</td>\n",
       "      <td>2019</td>\n",
       "      <td>294</td>\n",
       "      <td>if it staed with what american idolize first h...</td>\n",
       "      <td>staed american idolize first hollywood amp fir...</td>\n",
       "      <td>staed american idolize first hollywood amp fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Years  Tweet Length  \\\n",
       "0     big tipper  nice double entendre  awesome  so ...   2018           281   \n",
       "1                                                   ...   2018           313   \n",
       "2          smh  today s  movement is abt women no lo...   2018           284   \n",
       "3      cry  march  protest  amp  advocate for equali...   2018           285   \n",
       "1500                      if    it staed with what a...   2019           294   \n",
       "\n",
       "                                             Lemmatized  \\\n",
       "0     big tipper nice double entendre awesome so ins...   \n",
       "1     should n't we be suppoing this brave boy who c...   \n",
       "2     smh today s movement be abt woman no longer re...   \n",
       "3     cry march protest amp advocate for equality be...   \n",
       "1500  if it staed with what american idolize first h...   \n",
       "\n",
       "                               Tweets with no Stopwords  \\\n",
       "0     big tipper nice double entendre awesome instea...   \n",
       "1     n't suppoing brave boy come forward abuser mon...   \n",
       "2     smh today movement abt woman longer remain sil...   \n",
       "3     cry march protest amp advocate equality litera...   \n",
       "1500  staed american idolize first hollywood amp fir...   \n",
       "\n",
       "                                           Short Tweets  Target  \n",
       "0     big tipper nice double entendre awesome instea...       1  \n",
       "1     n't suppoing brave boy come forward abuser mon...       1  \n",
       "2     smh today movement abt woman longer remain sil...       1  \n",
       "3     cry march protest amp advocate equality litera...       1  \n",
       "1500  staed american idolize first hollywood amp fir...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print one instance of the data\n",
    "train.iloc[[0, 1, 2, 3, 1500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "normal-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1329,)\n",
      "smh today s movement be abt woman no longer remain silent amp men be hold accountable that be not the case before i don t doubt bc be a womanizer bc amp lewinsky be an adult consensual blow job ford be yo bk attempt rape not anywhere near the same\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[\"Lemmatized\"], train[\"Target\"], random_state = 1)\n",
    "print(X_train.shape)\n",
    "print(X_train[2])\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coordinated-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1329, 6812, 1) (1329,)\n",
      "(444, 6812, 1) (444,)\n",
      "[2.94026549 0.60244787]\n",
      "{0: 2.940265486725664, 1: 0.6024478694469628}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shilp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass classes=[0 1], y=[1 1 1 ... 1 1 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# create bag-of-words with weights using tfid vectoriser\n",
    "# strip accents and remove stop words during vectorisation\n",
    "tf=TfidfVectorizer(strip_accents = 'ascii', stop_words='english')\n",
    "\n",
    "# transform and fit the training set with vectoriser\n",
    "X_train_tf = tf.fit_transform(X_train).todense()\n",
    "X_train_tf_3 = X_train_tf[..., None]\n",
    "#X_train_pd = pd.DataFrame(X_train_tf, columns = tf.get_feature_names())\n",
    "# transform the test set with vectoriser\n",
    "X_test_tf = tf.transform(X_test).todense()\n",
    "X_test_tf_3 = X_test_tf[..., None]\n",
    "#X_test_pd = pd.DataFrame(X_test_tf, columns = tf.get_feature_names())\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "print(X_train_tf_3.shape, y_train.shape)\n",
    "print(X_test_tf_3.shape, y_test.shape)\n",
    "\n",
    "label_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train.ravel())\n",
    "print(label_weights)\n",
    "label_weights = {i:label_weights[i] for i in range(len(label_weights))} # Create dictionary\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "english-blake",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1447    1\n",
      "1286    1\n",
      "858     1\n",
      "1578    0\n",
      "351     1\n",
      "       ..\n",
      "1539    0\n",
      "1594    0\n",
      "771     1\n",
      "353     1\n",
      "1670    0\n",
      "Name: Target, Length: 444, dtype: int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "# create logistic regression model\n",
    "logreg = LogisticRegression(verbose=1, random_state=0, penalty='l2', solver='newton-cg')\n",
    "# train model on  vectorised training data\n",
    "model = logreg.fit(X_train_tf, y_train)\n",
    "# evaluate model performance on the test set\n",
    "pred = model.predict(X_test_tf)\n",
    "print(pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "casual-bobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445945945945946"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as st\n",
    "st.mean(pred - y_test)\n",
    "st.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "divided-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining A CNN Model\n",
    "def define_base_model(dropout_rate, l1_value, l2_value):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, (2), input_shape=(6812, 1), kernel_regularizer = regularizers.l1_l2(l1 = l1_value, l2 = l2_value), \n",
    "                     activation= 'relu', name = \"Conv1\")) \n",
    "    model.add(MaxPooling1D(2, name = \"MaxP1\"))\n",
    " \n",
    "    model.add(Conv1D(64, (2), name = \"Conv2\", activation='relu'))\n",
    "    model.add(MaxPooling1D(2, name = \"MaxP2\"))\n",
    " \n",
    "    model.add(Conv1D(64, (2), name = \"Conv3\", activation='relu'))\n",
    "    model.add(MaxPooling1D(2, name = \"MaxP3\"))\n",
    "    \n",
    "    model.add(Conv1D(64, (2), name = \"Conv4\", kernel_regularizer = regularizers.l1_l2(l1 = l1_value, l2 = l2_value),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling1D(2, name = \"MaxP4\"))\n",
    "    \n",
    "    model.add(Conv1D(64, (2), name = \"Conv5\", activation='relu'))\n",
    "    model.add(MaxPooling1D(2, name = \"MaxP5\"))\n",
    "    \n",
    "    model.add(Conv1D(64, (2), name = \"Conv6\", kernel_regularizer = regularizers.l1_l2(l1 = l1_value, l2 = l2_value),\n",
    "                       activation='relu'))\n",
    "    model.add(MaxPooling1D(2, name = \"MaxP6\"))\n",
    "    \n",
    "    model.add(Conv1D(64, (2), name = \"Conv7\", activation='relu'))\n",
    "    model.add(MaxPooling1D(2, name = \"MaxP7\"))\n",
    " \n",
    "    model.add(Flatten(name = \"Flat1\"))\n",
    "    model.add(Dense(1024, activation='relu', name = \"Dense1\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(2, activation='softmax', name = \"Output\"))\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795358ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the  1 / 48  model\n",
      "Epoch 1/8\n",
      "42/42 [==============================] - 26s 567ms/step - loss: 38.5580 - accuracy: 0.7751 - val_loss: 23.3237 - val_accuracy: 0.8446\n",
      "Epoch 2/8\n",
      "39/42 [==========================>...] - ETA: 1s - loss: 19.8360 - accuracy: 0.8309"
     ]
    }
   ],
   "source": [
    "# Define the drop out grid\n",
    "dropout_grid = [0.1, 0.5, 0.9]\n",
    "l1_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "l2_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "tot = len(dropout_grid) * len(l1_grid) * len(l2_grid)\n",
    "\n",
    "# Variables for the best result\n",
    "scores = []\n",
    "best_history = [] # place holder\n",
    "best_ind = 0\n",
    "best_acc = 0\n",
    "\n",
    "# Loop through each combination\n",
    "pos = 0\n",
    "for ii in dropout_grid:\n",
    "    for jj in l1_grid:\n",
    "        for kk in l2_grid:\n",
    "            pos = pos + 1\n",
    "            print(\"Fitting the \", pos, \"/\", tot , \" model\")\n",
    "            # define the model\n",
    "            curr_model = define_base_model(ii, jj, kk)\n",
    "            \n",
    "            # train the model\n",
    "            curr_history = curr_model.fit(X_train_tf_3, y_train_encoded, epochs = 8, \n",
    "                                          validation_data = (X_test_tf_3, y_test_encoded), verbose = 1)\n",
    "            curr_acc = st.mean(curr_history.history['val_acc'][5:10])\n",
    "                        \n",
    "            # get prediction report\n",
    "            y_pred = curr_model.predict(val_X, batch_size=64, verbose=0)\n",
    "            y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "            scores.append(classification_report(val_y, y_pred_bool))\n",
    "            \n",
    "            # save the best result\n",
    "            if best_acc < curr_acc:\n",
    "                best_acc = curr_acc\n",
    "                best_ind = pos - 1\n",
    "                best_history = curr_history\n",
    "                \n",
    "print(best_acc)\n",
    "print(best_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "absolute-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 8s 597ms/step - loss: 0.6934 - accuracy: 0.1874 - val_loss: 0.6963 - val_accuracy: 0.1599\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 8s 582ms/step - loss: 0.6970 - accuracy: 0.6674 - val_loss: 0.7058 - val_accuracy: 0.1554\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 8s 581ms/step - loss: 0.6927 - accuracy: 0.1911 - val_loss: 0.7123 - val_accuracy: 0.2117\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 8s 584ms/step - loss: 0.6847 - accuracy: 0.5967 - val_loss: 0.7159 - val_accuracy: 0.4482\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 8s 583ms/step - loss: 0.6542 - accuracy: 0.5139 - val_loss: 0.6221 - val_accuracy: 0.6464\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 8s 582ms/step - loss: 0.6013 - accuracy: 0.7005 - val_loss: 0.7655 - val_accuracy: 0.4887\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 8s 581ms/step - loss: 0.5593 - accuracy: 0.6539 - val_loss: 0.7255 - val_accuracy: 0.5743\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 8s 583ms/step - loss: 0.4646 - accuracy: 0.7487 - val_loss: 0.8114 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 8s 580ms/step - loss: 0.3790 - accuracy: 0.8299 - val_loss: 0.6711 - val_accuracy: 0.7185\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 8s 586ms/step - loss: 0.2314 - accuracy: 0.9037 - val_loss: 0.8265 - val_accuracy: 0.7590\n"
     ]
    }
   ],
   "source": [
    "curr_history = base_model.fit(X_train_tf_3, y_train_encoded, epochs = 10, batch_size = 100,\n",
    "                              validation_data = (X_test_tf_3, y_test_encoded), class_weight = label_weights, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
