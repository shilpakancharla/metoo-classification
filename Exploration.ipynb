{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60336b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.util import ngrams\n",
    "from nltk import everygrams\n",
    "\n",
    "# Import custom functions\n",
    "from explore import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a14ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned dataset\n",
    "df = pd.read_csv('processed_data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f008d07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet                       1830\n",
       "Years                          0\n",
       "Lemmatized                  3220\n",
       "Tweets with no Stopwords    6230\n",
       "Short Tweets                6893\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cfc3c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048258"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382ab977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Years</th>\n",
       "      <th>Tweet Length</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Tweets with no Stopwords</th>\n",
       "      <th>Short Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh man       in like flynn    what a crack up ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>304</td>\n",
       "      <td>oh man in like flynn what a crack up #metoo #s...</td>\n",
       "      <td>oh man like flynn crack #metoo #sooriginal #ed...</td>\n",
       "      <td>man like flynn crack #metoo #sooriginal #edgy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ah     no   but i must admit                  ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>375</td>\n",
       "      <td>ah no but i must admit #trumptrain #sweden htt...</td>\n",
       "      <td>ah must admit #trumptrain #sweden http co ckmy...</td>\n",
       "      <td>must admit #trumptrain #sweden http ckmynymtsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>most                                          ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>283</td>\n",
       "      <td>most like for #metoo http t co en lcew x</td>\n",
       "      <td>like #metoo http co en lcew x</td>\n",
       "      <td>like #metoo http lcew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>283</td>\n",
       "      <td>that be #awesome #maga #break #fridayfeeling #...</td>\n",
       "      <td>#awesome #maga #break #fridayfeeling #roymoore...</td>\n",
       "      <td>#awesome #maga #break #fridayfeeling #roymoore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank        you                           ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>306</td>\n",
       "      <td>thank you #metoo #silencebreakers https t co z...</td>\n",
       "      <td>thank #metoo #silencebreakers https co z xwbeocmk</td>\n",
       "      <td>thank #metoo #silencebreakers https xwbeocmk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Years  Tweet Length  \\\n",
       "0  oh man       in like flynn    what a crack up ...   2017           304   \n",
       "1  ah     no   but i must admit                  ...   2017           375   \n",
       "2  most                                          ...   2017           283   \n",
       "3                                                ...   2017           283   \n",
       "4     thank        you                           ...   2017           306   \n",
       "\n",
       "                                          Lemmatized  \\\n",
       "0  oh man in like flynn what a crack up #metoo #s...   \n",
       "1  ah no but i must admit #trumptrain #sweden htt...   \n",
       "2           most like for #metoo http t co en lcew x   \n",
       "3  that be #awesome #maga #break #fridayfeeling #...   \n",
       "4  thank you #metoo #silencebreakers https t co z...   \n",
       "\n",
       "                            Tweets with no Stopwords  \\\n",
       "0  oh man like flynn crack #metoo #sooriginal #ed...   \n",
       "1  ah must admit #trumptrain #sweden http co ckmy...   \n",
       "2                      like #metoo http co en lcew x   \n",
       "3  #awesome #maga #break #fridayfeeling #roymoore...   \n",
       "4  thank #metoo #silencebreakers https co z xwbeocmk   \n",
       "\n",
       "                                        Short Tweets  \n",
       "0  man like flynn crack #metoo #sooriginal #edgy ...  \n",
       "1     must admit #trumptrain #sweden http ckmynymtsk  \n",
       "2                              like #metoo http lcew  \n",
       "3  #awesome #maga #break #fridayfeeling #roymoore...  \n",
       "4       thank #metoo #silencebreakers https xwbeocmk  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11d8cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55f9b044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041365"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5ac2a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet                       0\n",
       "Years                       0\n",
       "Lemmatized                  0\n",
       "Tweets with no Stopwords    0\n",
       "Short Tweets                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39a73b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286269"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = new_df.loc[df['Years'] == 2017]\n",
    "len(df_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4783b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638897"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018 = new_df.loc[df['Years'] == 2018]\n",
    "len(df_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5624a531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116199"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019 = new_df.loc[df['Years'] == 2019]\n",
    "len(df_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e8685",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb733eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Years</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Tweets with no Stopwords</th>\n",
       "      <th>Short Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59965</th>\n",
       "      <td>ik zeg nee en je duwt gewoon je tong in mij...</td>\n",
       "      <td>2017</td>\n",
       "      <td>ik zeg nee en je duwt gewoon je tong in mijn m...</td>\n",
       "      <td>ik zeg nee en je duwt gewoon je tong mijn mond...</td>\n",
       "      <td>zeg nee duwt gewoon tong mijn mond waarom fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59966</th>\n",
       "      <td>she put alcohol in my mouth and made me go t...</td>\n",
       "      <td>2017</td>\n",
       "      <td>she put alcohol in my mouth and make me go to ...</td>\n",
       "      <td>put alcohol mouth make go bedroom #metoo http ...</td>\n",
       "      <td>put alcohol mouth make bedroom #metoo http iuv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59967</th>\n",
       "      <td>heres something else that needs to end in     ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>here something else that need to end in as wel...</td>\n",
       "      <td>something else need end well fucking #metoo bu...</td>\n",
       "      <td>something else need end well fucking #metoo bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59968</th>\n",
       "      <td>in light of #metoo and all this  i feel this...</td>\n",
       "      <td>2017</td>\n",
       "      <td>in light of #metoo and all this i feel this be...</td>\n",
       "      <td>light #metoo feel necessary unfounately happen...</td>\n",
       "      <td>light #metoo feel necessary unfounately happen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59969</th>\n",
       "      <td>#metoo</td>\n",
       "      <td>2017</td>\n",
       "      <td>#metoo</td>\n",
       "      <td>#metoo</td>\n",
       "      <td>#metoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Years  \\\n",
       "59965     ik zeg nee en je duwt gewoon je tong in mij...   2017   \n",
       "59966    she put alcohol in my mouth and made me go t...   2017   \n",
       "59967  heres something else that needs to end in     ...   2017   \n",
       "59968    in light of #metoo and all this  i feel this...   2017   \n",
       "59969                                             #metoo   2017   \n",
       "\n",
       "                                              Lemmatized  \\\n",
       "59965  ik zeg nee en je duwt gewoon je tong in mijn m...   \n",
       "59966  she put alcohol in my mouth and make me go to ...   \n",
       "59967  here something else that need to end in as wel...   \n",
       "59968  in light of #metoo and all this i feel this be...   \n",
       "59969                                             #metoo   \n",
       "\n",
       "                                Tweets with no Stopwords  \\\n",
       "59965  ik zeg nee en je duwt gewoon je tong mijn mond...   \n",
       "59966  put alcohol mouth make go bedroom #metoo http ...   \n",
       "59967  something else need end well fucking #metoo bu...   \n",
       "59968  light #metoo feel necessary unfounately happen...   \n",
       "59969                                             #metoo   \n",
       "\n",
       "                                            Short Tweets  \n",
       "59965  zeg nee duwt gewoon tong mijn mond waarom fran...  \n",
       "59966  put alcohol mouth make bedroom #metoo http iuv...  \n",
       "59967  something else need end well fucking #metoo bu...  \n",
       "59968  light #metoo feel necessary unfounately happen...  \n",
       "59969                                             #metoo  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing n't with not and modifying other features\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\"n't\", \"not\")\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\"'ve\", \"\")\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\"'re\", \"\")\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\"wan na\", \"wanna\")\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\"gon na\", \"gonna\")\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\" '\", \"\")\n",
    "df_2017['Short Tweets'] = df_2017['Short Tweets'].str.replace(\"' \", \"\")\n",
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5558e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenize function\n",
    "df_2017['Tokenized'] = df_2017[df_2017['Short Tweets'].notna()]['Short Tweets'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e91ad0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017['Lemma Final Token'] = df_2017[df_2017['Lemmatized'].notna()]['Lemmatized'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd059e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Years</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Tweets with no Stopwords</th>\n",
       "      <th>Short Tweets</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Lemma Final Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59965</th>\n",
       "      <td>ik zeg nee en je duwt gewoon je tong in mij...</td>\n",
       "      <td>2017</td>\n",
       "      <td>ik zeg nee en je duwt gewoon je tong in mijn m...</td>\n",
       "      <td>ik zeg nee en je duwt gewoon je tong mijn mond...</td>\n",
       "      <td>zeg nee duwt gewoon tong mijn mond waarom fran...</td>\n",
       "      <td>[zeg, nee, duwt, gewoon, tong, mijn, mond, waa...</td>\n",
       "      <td>[ik, zeg, nee, en, je, duwt, gewoon, je, tong,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59966</th>\n",
       "      <td>she put alcohol in my mouth and made me go t...</td>\n",
       "      <td>2017</td>\n",
       "      <td>she put alcohol in my mouth and make me go to ...</td>\n",
       "      <td>put alcohol mouth make go bedroom #metoo http ...</td>\n",
       "      <td>put alcohol mouth make bedroom #metoo http iuv...</td>\n",
       "      <td>[put, alcohol, mouth, make, bedroom, #metoo, h...</td>\n",
       "      <td>[she, put, alcohol, in, my, mouth, and, make, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59967</th>\n",
       "      <td>heres something else that needs to end in     ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>here something else that need to end in as wel...</td>\n",
       "      <td>something else need end well fucking #metoo bu...</td>\n",
       "      <td>something else need end well fucking #metoo bu...</td>\n",
       "      <td>[something, else, need, end, well, fucking, #m...</td>\n",
       "      <td>[here, something, else, that, need, to, end, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59968</th>\n",
       "      <td>in light of #metoo and all this  i feel this...</td>\n",
       "      <td>2017</td>\n",
       "      <td>in light of #metoo and all this i feel this be...</td>\n",
       "      <td>light #metoo feel necessary unfounately happen...</td>\n",
       "      <td>light #metoo feel necessary unfounately happen...</td>\n",
       "      <td>[light, #metoo, feel, necessary, unfounately, ...</td>\n",
       "      <td>[in, light, of, #metoo, and, all, this, i, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59969</th>\n",
       "      <td>#metoo</td>\n",
       "      <td>2017</td>\n",
       "      <td>#metoo</td>\n",
       "      <td>#metoo</td>\n",
       "      <td>#metoo</td>\n",
       "      <td>[#metoo]</td>\n",
       "      <td>[#metoo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Years  \\\n",
       "59965     ik zeg nee en je duwt gewoon je tong in mij...   2017   \n",
       "59966    she put alcohol in my mouth and made me go t...   2017   \n",
       "59967  heres something else that needs to end in     ...   2017   \n",
       "59968    in light of #metoo and all this  i feel this...   2017   \n",
       "59969                                             #metoo   2017   \n",
       "\n",
       "                                              Lemmatized  \\\n",
       "59965  ik zeg nee en je duwt gewoon je tong in mijn m...   \n",
       "59966  she put alcohol in my mouth and make me go to ...   \n",
       "59967  here something else that need to end in as wel...   \n",
       "59968  in light of #metoo and all this i feel this be...   \n",
       "59969                                             #metoo   \n",
       "\n",
       "                                Tweets with no Stopwords  \\\n",
       "59965  ik zeg nee en je duwt gewoon je tong mijn mond...   \n",
       "59966  put alcohol mouth make go bedroom #metoo http ...   \n",
       "59967  something else need end well fucking #metoo bu...   \n",
       "59968  light #metoo feel necessary unfounately happen...   \n",
       "59969                                             #metoo   \n",
       "\n",
       "                                            Short Tweets  \\\n",
       "59965  zeg nee duwt gewoon tong mijn mond waarom fran...   \n",
       "59966  put alcohol mouth make bedroom #metoo http iuv...   \n",
       "59967  something else need end well fucking #metoo bu...   \n",
       "59968  light #metoo feel necessary unfounately happen...   \n",
       "59969                                             #metoo   \n",
       "\n",
       "                                               Tokenized  \\\n",
       "59965  [zeg, nee, duwt, gewoon, tong, mijn, mond, waa...   \n",
       "59966  [put, alcohol, mouth, make, bedroom, #metoo, h...   \n",
       "59967  [something, else, need, end, well, fucking, #m...   \n",
       "59968  [light, #metoo, feel, necessary, unfounately, ...   \n",
       "59969                                           [#metoo]   \n",
       "\n",
       "                                       Lemma Final Token  \n",
       "59965  [ik, zeg, nee, en, je, duwt, gewoon, je, tong,...  \n",
       "59966  [she, put, alcohol, in, my, mouth, and, make, ...  \n",
       "59967  [here, something, else, that, need, to, end, i...  \n",
       "59968  [in, light, of, #metoo, and, all, this, i, fee...  \n",
       "59969                                           [#metoo]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b79faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_2017 = get_token_frequency(df_2017['Tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49abd877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_count</th>\n",
       "      <th>doc_appeared</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#metoo</td>\n",
       "      <td>197966</td>\n",
       "      <td>196352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>http</td>\n",
       "      <td>159645</td>\n",
       "      <td>149872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https</td>\n",
       "      <td>62092</td>\n",
       "      <td>61731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>woman</td>\n",
       "      <td>37347</td>\n",
       "      <td>34970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>movement</td>\n",
       "      <td>25241</td>\n",
       "      <td>24951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>sexual</td>\n",
       "      <td>23772</td>\n",
       "      <td>23200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amp</td>\n",
       "      <td>14465</td>\n",
       "      <td>12955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>say</td>\n",
       "      <td>13573</td>\n",
       "      <td>12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>time</td>\n",
       "      <td>13362</td>\n",
       "      <td>12936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>men</td>\n",
       "      <td>12923</td>\n",
       "      <td>12194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>year</td>\n",
       "      <td>12775</td>\n",
       "      <td>12237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>harassment</td>\n",
       "      <td>11644</td>\n",
       "      <td>11533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147837</th>\n",
       "      <td>not</td>\n",
       "      <td>11087</td>\n",
       "      <td>10284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>like</td>\n",
       "      <td>10766</td>\n",
       "      <td>10445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>get</td>\n",
       "      <td>10731</td>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token  token_count  doc_appeared\n",
       "token_id                                       \n",
       "0             #metoo       197966        196352\n",
       "16              http       159645        149872\n",
       "29             https        62092         61731\n",
       "238            woman        37347         34970\n",
       "268         movement        25241         24951\n",
       "270           sexual        23772         23200\n",
       "46               amp        14465         12955\n",
       "186              say        13573         12995\n",
       "150             time        13362         12936\n",
       "140              men        12923         12194\n",
       "152             year        12775         12237\n",
       "284       harassment        11644         11533\n",
       "147837           not        11087         10284\n",
       "176             like        10766         10445\n",
       "608              get        10731         10363"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2017 = token_2017.sort_values(by = 'token_count', ascending = False)\n",
    "token_2017.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "378d1cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Years</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Tweets with no Stopwords</th>\n",
       "      <th>Short Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuando esta se ora habla es como leer los...</td>\n",
       "      <td>2018</td>\n",
       "      <td>cuando esta se ora habla e como leer los twit ...</td>\n",
       "      <td>cuando esta se ora habla e como leer los twit ...</td>\n",
       "      <td>cuando esta ora habla como leer los twit ivank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will require institutions that receive gra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>will require institution that receive grant fu...</td>\n",
       "      <td>require institution receive grant fund tell pi...</td>\n",
       "      <td>require institution receive grant fund tell pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>listening to the awesome feminist scholar cynt...</td>\n",
       "      <td>2018</td>\n",
       "      <td>listen to the awesome feminist scholar cynthia...</td>\n",
       "      <td>listen awesome feminist scholar cynthia enloe ...</td>\n",
       "      <td>listen awesome feminist scholar cynthia enloe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>http t co gwawglka</td>\n",
       "      <td>http co gwawglka</td>\n",
       "      <td>http gwawglka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a ver  donde est n todas las voceras colomb...</td>\n",
       "      <td>2018</td>\n",
       "      <td>a ver donde est n toda la voceras colombianas ...</td>\n",
       "      <td>ver donde est n toda la voceras colombianas de...</td>\n",
       "      <td>ver donde est toda voceras colombianas del #me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Years  \\\n",
       "0       cuando esta se ora habla es como leer los...   2018   \n",
       "1      will require institutions that receive gra...   2018   \n",
       "2  listening to the awesome feminist scholar cynt...   2018   \n",
       "3                                                ...   2018   \n",
       "4     a ver  donde est n todas las voceras colomb...   2018   \n",
       "\n",
       "                                          Lemmatized  \\\n",
       "0  cuando esta se ora habla e como leer los twit ...   \n",
       "1  will require institution that receive grant fu...   \n",
       "2  listen to the awesome feminist scholar cynthia...   \n",
       "3                                 http t co gwawglka   \n",
       "4  a ver donde est n toda la voceras colombianas ...   \n",
       "\n",
       "                            Tweets with no Stopwords  \\\n",
       "0  cuando esta se ora habla e como leer los twit ...   \n",
       "1  require institution receive grant fund tell pi...   \n",
       "2  listen awesome feminist scholar cynthia enloe ...   \n",
       "3                                   http co gwawglka   \n",
       "4  ver donde est n toda la voceras colombianas de...   \n",
       "\n",
       "                                        Short Tweets  \n",
       "0  cuando esta ora habla como leer los twit ivank...  \n",
       "1  require institution receive grant fund tell pi...  \n",
       "2  listen awesome feminist scholar cynthia enloe ...  \n",
       "3                                      http gwawglka  \n",
       "4  ver donde est toda voceras colombianas del #me...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing n't with not and modifying other features\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\"n't\", \"not\")\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\"'ve\", \"\")\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\"'re\", \"\")\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\"wan na\", \"wanna\")\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\"gon na\", \"gonna\")\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\" '\", \"\")\n",
    "df_2018['Short Tweets'] = df_2018['Short Tweets'].str.replace(\"' \", \"\")\n",
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee546a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_count</th>\n",
       "      <th>doc_appeared</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>woman</td>\n",
       "      <td>130210</td>\n",
       "      <td>108584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>movement</td>\n",
       "      <td>95236</td>\n",
       "      <td>90848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>amp</td>\n",
       "      <td>68968</td>\n",
       "      <td>50423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98260</th>\n",
       "      <td>not</td>\n",
       "      <td>55744</td>\n",
       "      <td>47837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sexual</td>\n",
       "      <td>52881</td>\n",
       "      <td>49839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>say</td>\n",
       "      <td>47540</td>\n",
       "      <td>43374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>get</td>\n",
       "      <td>46393</td>\n",
       "      <td>42627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>men</td>\n",
       "      <td>43786</td>\n",
       "      <td>37895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>like</td>\n",
       "      <td>42011</td>\n",
       "      <td>38866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>#metoo</td>\n",
       "      <td>36822</td>\n",
       "      <td>36467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>one</td>\n",
       "      <td>36453</td>\n",
       "      <td>33827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>make</td>\n",
       "      <td>34767</td>\n",
       "      <td>32750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>people</td>\n",
       "      <td>32340</td>\n",
       "      <td>29528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>time</td>\n",
       "      <td>31829</td>\n",
       "      <td>30057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>take</td>\n",
       "      <td>29963</td>\n",
       "      <td>28407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  token_count  doc_appeared\n",
       "token_id                                     \n",
       "68           woman       130210        108584\n",
       "29        movement        95236         90848\n",
       "90             amp        68968         50423\n",
       "98260          not        55744         47837\n",
       "84          sexual        52881         49839\n",
       "452            say        47540         43374\n",
       "135            get        46393         42627\n",
       "436            men        43786         37895\n",
       "342           like        42011         38866\n",
       "21          #metoo        36822         36467\n",
       "314            one        36453         33827\n",
       "192           make        34767         32750\n",
       "215         people        32340         29528\n",
       "140           time        31829         30057\n",
       "244           take        29963         28407"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenize function\n",
    "df_2018['Tokenized'] = df_2018[df_2018['Short Tweets'].notna()]['Short Tweets'].apply(tokenize)\n",
    "df_2018['Lemma Final Token'] = df_2018[df_2018['Lemmatized'].notna()]['Lemmatized'].apply(tokenize)\n",
    "token_2018 = get_token_frequency(df_2018['Tokenized'])\n",
    "token_2018 = token_2018.sort_values(by = 'token_count', ascending = False)\n",
    "token_2018.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a3da04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Years</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Tweets with no Stopwords</th>\n",
       "      <th>Short Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>931524</th>\n",
       "      <td>ex prosecutor and</td>\n",
       "      <td>2019</td>\n",
       "      <td>ex prosecutor and</td>\n",
       "      <td>ex prosecutor</td>\n",
       "      <td>prosecutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931525</th>\n",
       "      <td>thread on the raw realities of a woman s  psyc...</td>\n",
       "      <td>2019</td>\n",
       "      <td>thread on the raw reality of a woman s psychol...</td>\n",
       "      <td>thread raw reality woman psychological affect ...</td>\n",
       "      <td>thread raw reality woman psychological affect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931526</th>\n",
       "      <td>things  predators send on ceain days  holidays...</td>\n",
       "      <td>2019</td>\n",
       "      <td>thing predator send on ceain day holiday etc l...</td>\n",
       "      <td>thing predator send ceain day holiday etc like...</td>\n",
       "      <td>thing predator send ceain day holiday etc like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931527</th>\n",
       "      <td>let s leave insisting people must forgive thei...</td>\n",
       "      <td>2019</td>\n",
       "      <td>let s leave insist people must forgive their a...</td>\n",
       "      <td>let leave insist people must forgive abuser heal</td>\n",
       "      <td>let leave insist people must forgive abuser heal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931528</th>\n",
       "      <td>instead of the  movement  i'm hoping      sees...</td>\n",
       "      <td>2019</td>\n",
       "      <td>instead of the movement i'm hop see the moveme...</td>\n",
       "      <td>instead movement i'm hop see movement indictme...</td>\n",
       "      <td>instead movement i'm hop see movement indictme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet  Years  \\\n",
       "931524                        ex prosecutor and             2019   \n",
       "931525  thread on the raw realities of a woman s  psyc...   2019   \n",
       "931526  things  predators send on ceain days  holidays...   2019   \n",
       "931527  let s leave insisting people must forgive thei...   2019   \n",
       "931528  instead of the  movement  i'm hoping      sees...   2019   \n",
       "\n",
       "                                               Lemmatized  \\\n",
       "931524                                  ex prosecutor and   \n",
       "931525  thread on the raw reality of a woman s psychol...   \n",
       "931526  thing predator send on ceain day holiday etc l...   \n",
       "931527  let s leave insist people must forgive their a...   \n",
       "931528  instead of the movement i'm hop see the moveme...   \n",
       "\n",
       "                                 Tweets with no Stopwords  \\\n",
       "931524                                      ex prosecutor   \n",
       "931525  thread raw reality woman psychological affect ...   \n",
       "931526  thing predator send ceain day holiday etc like...   \n",
       "931527   let leave insist people must forgive abuser heal   \n",
       "931528  instead movement i'm hop see movement indictme...   \n",
       "\n",
       "                                             Short Tweets  \n",
       "931524                                         prosecutor  \n",
       "931525  thread raw reality woman psychological affect ...  \n",
       "931526  thing predator send ceain day holiday etc like...  \n",
       "931527   let leave insist people must forgive abuser heal  \n",
       "931528  instead movement i'm hop see movement indictme...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing n't with not and modifying other features\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\"n't\", \"not\")\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\"'ve\", \"\")\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\"'re\", \"\")\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\"wan na\", \"wanna\")\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\"gon na\", \"gonna\")\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\" '\", \"\")\n",
    "df_2019['Short Tweets'] = df_2019['Short Tweets'].str.replace(\"' \", \"\")\n",
    "df_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c31de983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_count</th>\n",
       "      <th>doc_appeared</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>woman</td>\n",
       "      <td>22645</td>\n",
       "      <td>18589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>movement</td>\n",
       "      <td>18491</td>\n",
       "      <td>17751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>amp</td>\n",
       "      <td>13251</td>\n",
       "      <td>9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>men</td>\n",
       "      <td>10722</td>\n",
       "      <td>8909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>not</td>\n",
       "      <td>10673</td>\n",
       "      <td>9149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>get</td>\n",
       "      <td>10534</td>\n",
       "      <td>9632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sexual</td>\n",
       "      <td>9795</td>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>like</td>\n",
       "      <td>8899</td>\n",
       "      <td>8232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>say</td>\n",
       "      <td>8079</td>\n",
       "      <td>7402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>make</td>\n",
       "      <td>6959</td>\n",
       "      <td>6547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>people</td>\n",
       "      <td>6912</td>\n",
       "      <td>6248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>one</td>\n",
       "      <td>6325</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>know</td>\n",
       "      <td>6087</td>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>think</td>\n",
       "      <td>5818</td>\n",
       "      <td>5433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>need</td>\n",
       "      <td>5445</td>\n",
       "      <td>5091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  token_count  doc_appeared\n",
       "token_id                                     \n",
       "9            woman        22645         18589\n",
       "35        movement        18491         17751\n",
       "59             amp        13251          9643\n",
       "87             men        10722          8909\n",
       "157            not        10673          9149\n",
       "106            get        10534          9632\n",
       "54          sexual         9795          9129\n",
       "17            like         8899          8232\n",
       "152            say         8079          7402\n",
       "333           make         6959          6547\n",
       "30          people         6912          6248\n",
       "108            one         6325          5894\n",
       "195           know         6087          5604\n",
       "197          think         5818          5433\n",
       "238           need         5445          5091"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenize function\n",
    "df_2019['Tokenized'] = df_2019[df_2019['Short Tweets'].notna()]['Short Tweets'].apply(tokenize)\n",
    "df_2019['Lemma Final Token'] = df_2019[df_2019['Lemmatized'].notna()]['Lemmatized'].apply(tokenize)\n",
    "token_2019 = get_token_frequency(df_2019['Tokenized'])\n",
    "token_2019 = token_2019.sort_values(by = 'token_count', ascending = False)\n",
    "token_2019.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2f8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
