{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "pacific-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install keras==2.4.0\n",
    "import tensorflow\n",
    "import keras\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Activation, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "overhead-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wqe3stue) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1803<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/shilpakancharla/Documents/metoo-classification/wandb/run-20210418_135535-wqe3stue/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/shilpakancharla/Documents/metoo-classification/wandb/run-20210418_135535-wqe3stue/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">avid-snowflake-1</strong>: <a href=\"https://wandb.ai/shilpakancharla/metoo-classification/runs/wqe3stue\" target=\"_blank\">https://wandb.ai/shilpakancharla/metoo-classification/runs/wqe3stue</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:wqe3stue). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">worthy-galaxy-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/shilpakancharla/metoo-classification\" target=\"_blank\">https://wandb.ai/shilpakancharla/metoo-classification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/shilpakancharla/metoo-classification/runs/s61f6r1m\" target=\"_blank\">https://wandb.ai/shilpakancharla/metoo-classification/runs/s61f6r1m</a><br/>\n",
       "                Run data is saved locally in <code>/Users/shilpakancharla/Documents/metoo-classification/wandb/run-20210418_135604-s61f6r1m</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "# Set parameters\n",
    "config.vocab_size = 1000\n",
    "config.maxlen = 1000\n",
    "config.batch_size = 32\n",
    "config.embedding_dims = 10\n",
    "config.filters = 16\n",
    "config.kernel_size = 3\n",
    "config.hidden_dims = 250\n",
    "config.epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "raised-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018, 2017, 2019])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data/clean_data.csv')\n",
    "df.dropna()\n",
    "delete_row = df[df['Years'] == 0].index\n",
    "df = df.drop(delete_row)\n",
    "df['Years'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "floating-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweets with no Stopwords'], df['Years'], test_size = 0.33,\n",
    "                                                   random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hungry-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words = config.vocab_size)\n",
    "tokenizer.fit_on_texts(X_train.astype(str))\n",
    "X_train_tokenized = tokenizer.texts_to_matrix(X_train.astype(str))\n",
    "X_test_tokenized = tokenizer.texts_to_matrix(X_test.astype(str))\n",
    "X_train_seq = sequence.pad_sequences(X_train_tokenized, maxlen = config.maxlen)\n",
    "X_test_seq = sequence.pad_sequences(X_test_tokenized, maxlen = config.maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "preliminary-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_encoded = LabelBinarizer().fit_transform(y_train)\n",
    "y_test_encoded = LabelBinarizer().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "olympic-metabolism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.21118492 0.5432297  2.99831792]\n",
      "{0: 1.21118492304933, 1: 0.5432297008596592, 2: 2.9983179213948445}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[2017 2018 2019], y=[2017 2018 2018 ... 2017 2017 2018] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "label_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train.ravel())\n",
    "print(label_weights)\n",
    "label_weights = {i:label_weights[i] for i in range(len(label_weights))} # Create dictionary\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tight-proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702308, 1000)\n",
      "(345913, 1000)\n",
      "(702308, 3)\n",
      "(345913, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(X_train_seq.shape)\n",
    "print(X_test_seq.shape)\n",
    "print(y_train_encoded.shape)\n",
    "print(y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "english-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "\n",
    "def define_cnn_model(dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(config.vocab_size, config.embedding_dims, input_length = config.maxlen))\n",
    "    model.add(Conv1D(config.filters, config.kernel_size, padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(config.filters, config.kernel_size, padding = 'valid', activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(config.hidden_dims, activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "formed-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the  1 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 953s 1ms/step - loss: 0.6446 - acc: 0.6431 - val_loss: 0.6373 - val_acc: 0.6860\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 934s 1ms/step - loss: 0.5710 - acc: 0.6736 - val_loss: 0.6354 - val_acc: 0.6782\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 927s 1ms/step - loss: 0.5486 - acc: 0.6952 - val_loss: 0.6211 - val_acc: 0.6963\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 967s 1ms/step - loss: 0.5290 - acc: 0.7123 - val_loss: 0.6096 - val_acc: 0.7033\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 1119s 2ms/step - loss: 0.5099 - acc: 0.7269 - val_loss: 0.6068 - val_acc: 0.7145\n",
      "Fitting the  2 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 990s 1ms/step - loss: 0.6261 - acc: 0.6496 - val_loss: 0.6030 - val_acc: 0.7151\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 971s 1ms/step - loss: 0.5644 - acc: 0.6779 - val_loss: 0.6086 - val_acc: 0.6917\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 950s 1ms/step - loss: 0.5428 - acc: 0.7005 - val_loss: 0.6343 - val_acc: 0.6715\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 1015s 1ms/step - loss: 0.5230 - acc: 0.7192 - val_loss: 0.5958 - val_acc: 0.7160\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 954s 1ms/step - loss: 0.5048 - acc: 0.7333 - val_loss: 0.5940 - val_acc: 0.7107\n",
      "Fitting the  3 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 972s 1ms/step - loss: 0.6211 - acc: 0.6546 - val_loss: 0.6182 - val_acc: 0.6983\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 955s 1ms/step - loss: 0.5635 - acc: 0.6793 - val_loss: 0.6400 - val_acc: 0.6566\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 957s 1ms/step - loss: 0.5431 - acc: 0.7015 - val_loss: 0.6027 - val_acc: 0.7053\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 969s 1ms/step - loss: 0.5214 - acc: 0.7186 - val_loss: 0.5922 - val_acc: 0.7101\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 961s 1ms/step - loss: 0.5023 - acc: 0.7342 - val_loss: 0.5776 - val_acc: 0.7358\n",
      "Fitting the  4 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 964s 1ms/step - loss: 0.6206 - acc: 0.6546 - val_loss: 0.6674 - val_acc: 0.6215\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 956s 1ms/step - loss: 0.5651 - acc: 0.6786 - val_loss: 0.6221 - val_acc: 0.6831\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 956s 1ms/step - loss: 0.5447 - acc: 0.6997 - val_loss: 0.6058 - val_acc: 0.7057\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 953s 1ms/step - loss: 0.5235 - acc: 0.7187 - val_loss: 0.6220 - val_acc: 0.6922\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 966s 1ms/step - loss: 0.5038 - acc: 0.7330 - val_loss: 0.6708 - val_acc: 0.6334\n",
      "Fitting the  5 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.6139 - acc: 0.6546 - val_loss: 0.6616 - val_acc: 0.6125\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.5615 - acc: 0.6840 - val_loss: 0.6345 - val_acc: 0.6550\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 919s 1ms/step - loss: 0.5397 - acc: 0.7062 - val_loss: 0.6162 - val_acc: 0.6890\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 954s 1ms/step - loss: 0.5188 - acc: 0.7234 - val_loss: 0.6273 - val_acc: 0.6740\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 958s 1ms/step - loss: 0.4982 - acc: 0.7371 - val_loss: 0.5962 - val_acc: 0.7159\n",
      "Fitting the  6 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 961s 1ms/step - loss: 0.6108 - acc: 0.6558 - val_loss: 0.6197 - val_acc: 0.6718\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 957s 1ms/step - loss: 0.5629 - acc: 0.6821 - val_loss: 0.6235 - val_acc: 0.6752\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.5418 - acc: 0.7024 - val_loss: 0.6184 - val_acc: 0.6919\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 860s 1ms/step - loss: 0.5209 - acc: 0.7197 - val_loss: 0.5994 - val_acc: 0.7075\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 855s 1ms/step - loss: 0.4985 - acc: 0.7350 - val_loss: 0.5947 - val_acc: 0.7242\n",
      "Fitting the  7 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.6140 - acc: 0.6512 - val_loss: 0.6150 - val_acc: 0.6976\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 850s 1ms/step - loss: 0.5593 - acc: 0.6828 - val_loss: 0.6123 - val_acc: 0.7078\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 845s 1ms/step - loss: 0.5352 - acc: 0.7083 - val_loss: 0.6203 - val_acc: 0.6873\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 848s 1ms/step - loss: 0.5136 - acc: 0.7269 - val_loss: 0.6039 - val_acc: 0.7166\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 850s 1ms/step - loss: 0.4944 - acc: 0.7407 - val_loss: 0.6393 - val_acc: 0.6925\n",
      "Fitting the  8 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 853s 1ms/step - loss: 0.6086 - acc: 0.6567 - val_loss: 0.6437 - val_acc: 0.6569\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 851s 1ms/step - loss: 0.5627 - acc: 0.6799 - val_loss: 0.5751 - val_acc: 0.7483\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 851s 1ms/step - loss: 0.5406 - acc: 0.7013 - val_loss: 0.6548 - val_acc: 0.6530\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5201 - acc: 0.7201 - val_loss: 0.6174 - val_acc: 0.6888\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 860s 1ms/step - loss: 0.5002 - acc: 0.7344 - val_loss: 0.6135 - val_acc: 0.7021\n",
      "Epoch 00005: early stopping\n",
      "Fitting the  9 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 847s 1ms/step - loss: 0.6058 - acc: 0.6537 - val_loss: 0.6244 - val_acc: 0.6903\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 844s 1ms/step - loss: 0.5582 - acc: 0.6826 - val_loss: 0.6024 - val_acc: 0.7110\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 844s 1ms/step - loss: 0.5340 - acc: 0.7073 - val_loss: 0.6155 - val_acc: 0.6907\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 847s 1ms/step - loss: 0.5107 - acc: 0.7273 - val_loss: 0.5900 - val_acc: 0.7111\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 844s 1ms/step - loss: 0.4904 - acc: 0.7421 - val_loss: 0.6036 - val_acc: 0.7090\n",
      "Fitting the  10 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 851s 1ms/step - loss: 0.6039 - acc: 0.6551 - val_loss: 0.6577 - val_acc: 0.6251\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5594 - acc: 0.6803 - val_loss: 0.6484 - val_acc: 0.6241\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 850s 1ms/step - loss: 0.5379 - acc: 0.7026 - val_loss: 0.6132 - val_acc: 0.6927\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 850s 1ms/step - loss: 0.5166 - acc: 0.7207 - val_loss: 0.6227 - val_acc: 0.6792\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 858s 1ms/step - loss: 0.4977 - acc: 0.7343 - val_loss: 0.6359 - val_acc: 0.6701\n",
      "Fitting the  11 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.6032 - acc: 0.6552 - val_loss: 0.6194 - val_acc: 0.6884\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 855s 1ms/step - loss: 0.5601 - acc: 0.6811 - val_loss: 0.6299 - val_acc: 0.6732\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702308/702308 [==============================] - 859s 1ms/step - loss: 0.5370 - acc: 0.7050 - val_loss: 0.6028 - val_acc: 0.7027\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5150 - acc: 0.7231 - val_loss: 0.6120 - val_acc: 0.7057\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 854s 1ms/step - loss: 0.4947 - acc: 0.7373 - val_loss: 0.5940 - val_acc: 0.7076\n",
      "Fitting the  12 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 922s 1ms/step - loss: 0.6037 - acc: 0.6556 - val_loss: 0.6421 - val_acc: 0.6373\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 920s 1ms/step - loss: 0.5598 - acc: 0.6834 - val_loss: 0.6442 - val_acc: 0.6377\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 956s 1ms/step - loss: 0.5361 - acc: 0.7061 - val_loss: 0.5793 - val_acc: 0.7350\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 952s 1ms/step - loss: 0.5130 - acc: 0.7246 - val_loss: 0.6122 - val_acc: 0.6879\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 952s 1ms/step - loss: 0.4913 - acc: 0.7391 - val_loss: 0.5559 - val_acc: 0.7569\n",
      "Fitting the  13 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 959s 1ms/step - loss: 0.6031 - acc: 0.6565 - val_loss: 0.6276 - val_acc: 0.6650\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 953s 1ms/step - loss: 0.5573 - acc: 0.6846 - val_loss: 0.6121 - val_acc: 0.7014\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 953s 1ms/step - loss: 0.5329 - acc: 0.7080 - val_loss: 0.5954 - val_acc: 0.7180\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 963s 1ms/step - loss: 0.5105 - acc: 0.7268 - val_loss: 0.6270 - val_acc: 0.6830\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 954s 1ms/step - loss: 0.4907 - acc: 0.7413 - val_loss: 0.6108 - val_acc: 0.6928\n",
      "Fitting the  14 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1282s 2ms/step - loss: 0.5981 - acc: 0.6555 - val_loss: 0.6076 - val_acc: 0.6925\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1077s 2ms/step - loss: 0.5563 - acc: 0.6842 - val_loss: 0.6451 - val_acc: 0.6570\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 1099s 2ms/step - loss: 0.5317 - acc: 0.7097 - val_loss: 0.6109 - val_acc: 0.6957\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 1046s 1ms/step - loss: 0.5088 - acc: 0.7284 - val_loss: 0.5742 - val_acc: 0.7342\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 1000s 1ms/step - loss: 0.4877 - acc: 0.7430 - val_loss: 0.6100 - val_acc: 0.7080\n",
      "Fitting the  15 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 956s 1ms/step - loss: 0.6014 - acc: 0.6573 - val_loss: 0.6160 - val_acc: 0.6956\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1215s 2ms/step - loss: 0.5572 - acc: 0.6830 - val_loss: 0.6123 - val_acc: 0.6993\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 1180s 2ms/step - loss: 0.5326 - acc: 0.7064 - val_loss: 0.5942 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 961s 1ms/step - loss: 0.5102 - acc: 0.7247 - val_loss: 0.5880 - val_acc: 0.7240\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 1330s 2ms/step - loss: 0.4894 - acc: 0.7393 - val_loss: 0.5998 - val_acc: 0.7178\n",
      "Fitting the  16 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1412s 2ms/step - loss: 0.5994 - acc: 0.6564 - val_loss: 0.6122 - val_acc: 0.6910\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1304s 2ms/step - loss: 0.5557 - acc: 0.6849 - val_loss: 0.6594 - val_acc: 0.6400\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 1130s 2ms/step - loss: 0.5310 - acc: 0.7113 - val_loss: 0.6260 - val_acc: 0.6811\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 1056s 2ms/step - loss: 0.5082 - acc: 0.7301 - val_loss: 0.6492 - val_acc: 0.6579\n",
      "Epoch 00004: early stopping\n",
      "Fitting the  17 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 974s 1ms/step - loss: 0.6379 - acc: 0.6454 - val_loss: 0.6521 - val_acc: 0.6179\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 993s 1ms/step - loss: 0.5797 - acc: 0.6663 - val_loss: 0.6488 - val_acc: 0.6439\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 968s 1ms/step - loss: 0.5698 - acc: 0.6825 - val_loss: 0.6354 - val_acc: 0.6738\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 966s 1ms/step - loss: 0.5630 - acc: 0.6926 - val_loss: 0.5962 - val_acc: 0.7245\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 979s 1ms/step - loss: 0.5566 - acc: 0.7004 - val_loss: 0.6242 - val_acc: 0.6872\n",
      "Fitting the  18 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 987s 1ms/step - loss: 0.6500 - acc: 0.6372 - val_loss: 0.6745 - val_acc: 0.6335\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1033s 1ms/step - loss: 0.6044 - acc: 0.6519 - val_loss: 0.6542 - val_acc: 0.6808\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 962s 1ms/step - loss: 0.5973 - acc: 0.6620 - val_loss: 0.6421 - val_acc: 0.6811\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 982s 1ms/step - loss: 0.5933 - acc: 0.6734 - val_loss: 0.6417 - val_acc: 0.6867\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 971s 1ms/step - loss: 0.5877 - acc: 0.6795 - val_loss: 0.6628 - val_acc: 0.6460\n",
      "Fitting the  19 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1020s 1ms/step - loss: 0.6321 - acc: 0.6493 - val_loss: 0.6792 - val_acc: 0.5994\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 983s 1ms/step - loss: 0.5809 - acc: 0.6662 - val_loss: 0.6200 - val_acc: 0.6779\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 1022s 1ms/step - loss: 0.5715 - acc: 0.6804 - val_loss: 0.6146 - val_acc: 0.6973\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 1002s 1ms/step - loss: 0.5640 - acc: 0.6888 - val_loss: 0.6005 - val_acc: 0.7184\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 1275s 2ms/step - loss: 0.5588 - acc: 0.6974 - val_loss: 0.6012 - val_acc: 0.7255\n",
      "Fitting the  20 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1373s 2ms/step - loss: 0.6279 - acc: 0.6488 - val_loss: 0.6494 - val_acc: 0.6696\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1292s 2ms/step - loss: 0.5781 - acc: 0.6689 - val_loss: 0.6185 - val_acc: 0.6993\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 972s 1ms/step - loss: 0.5692 - acc: 0.6805 - val_loss: 0.6049 - val_acc: 0.6970\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 977s 1ms/step - loss: 0.5620 - acc: 0.6914 - val_loss: 0.6261 - val_acc: 0.6885\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 986s 1ms/step - loss: 0.5558 - acc: 0.6991 - val_loss: 0.6153 - val_acc: 0.6890\n",
      "Fitting the  21 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 976s 1ms/step - loss: 0.6263 - acc: 0.6440 - val_loss: 0.6492 - val_acc: 0.6370\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 973s 1ms/step - loss: 0.5789 - acc: 0.6634 - val_loss: 0.6234 - val_acc: 0.6816\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 973s 1ms/step - loss: 0.5682 - acc: 0.6794 - val_loss: 0.6191 - val_acc: 0.6836\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 953s 1ms/step - loss: 0.5617 - acc: 0.6892 - val_loss: 0.6226 - val_acc: 0.6831\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 854s 1ms/step - loss: 0.5557 - acc: 0.6983 - val_loss: 0.6197 - val_acc: 0.6898\n",
      "Fitting the  22 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702308/702308 [==============================] - 854s 1ms/step - loss: 0.6215 - acc: 0.6468 - val_loss: 0.6319 - val_acc: 0.6819\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 866s 1ms/step - loss: 0.5789 - acc: 0.6657 - val_loss: 0.6232 - val_acc: 0.6869\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5691 - acc: 0.6799 - val_loss: 0.6332 - val_acc: 0.6669\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 865s 1ms/step - loss: 0.5607 - acc: 0.6949 - val_loss: 0.6344 - val_acc: 0.6738\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.5540 - acc: 0.7012 - val_loss: 0.6170 - val_acc: 0.6798\n",
      "Fitting the  23 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.6372 - acc: 0.6360 - val_loss: 0.7083 - val_acc: 0.5855\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.6029 - acc: 0.6492 - val_loss: 0.6565 - val_acc: 0.6509\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 862s 1ms/step - loss: 0.5959 - acc: 0.6615 - val_loss: 0.6407 - val_acc: 0.6871\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.5899 - acc: 0.6704 - val_loss: 0.6619 - val_acc: 0.6357\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 855s 1ms/step - loss: 0.5868 - acc: 0.6764 - val_loss: 0.6397 - val_acc: 0.6750\n",
      "Fitting the  24 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 863s 1ms/step - loss: 0.6182 - acc: 0.6480 - val_loss: 0.6429 - val_acc: 0.6362\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 858s 1ms/step - loss: 0.5760 - acc: 0.6688 - val_loss: 0.6336 - val_acc: 0.6506\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5655 - acc: 0.6842 - val_loss: 0.6272 - val_acc: 0.6794\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 856s 1ms/step - loss: 0.5578 - acc: 0.6953 - val_loss: 0.6258 - val_acc: 0.6696\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 859s 1ms/step - loss: 0.5513 - acc: 0.7030 - val_loss: 0.6028 - val_acc: 0.7142\n",
      "Fitting the  25 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 855s 1ms/step - loss: 0.6171 - acc: 0.6444 - val_loss: 0.6165 - val_acc: 0.6853\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 860s 1ms/step - loss: 0.5763 - acc: 0.6670 - val_loss: 0.6240 - val_acc: 0.6560\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 852s 1ms/step - loss: 0.5666 - acc: 0.6813 - val_loss: 0.5915 - val_acc: 0.7269\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 855s 1ms/step - loss: 0.5593 - acc: 0.6927 - val_loss: 0.6484 - val_acc: 0.6391\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 856s 1ms/step - loss: 0.5535 - acc: 0.6994 - val_loss: 0.6036 - val_acc: 0.6985\n",
      "Fitting the  26 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 864s 1ms/step - loss: 0.6137 - acc: 0.6482 - val_loss: 0.6574 - val_acc: 0.6190\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 850s 1ms/step - loss: 0.5753 - acc: 0.6702 - val_loss: 0.6373 - val_acc: 0.6523\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 858s 1ms/step - loss: 0.5652 - acc: 0.6840 - val_loss: 0.6075 - val_acc: 0.6994\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 863s 1ms/step - loss: 0.5581 - acc: 0.6960 - val_loss: 0.5880 - val_acc: 0.7297\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 862s 1ms/step - loss: 0.5513 - acc: 0.7038 - val_loss: 0.5950 - val_acc: 0.7201\n",
      "Fitting the  27 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.6145 - acc: 0.6479 - val_loss: 0.6750 - val_acc: 0.5839\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5755 - acc: 0.6675 - val_loss: 0.5963 - val_acc: 0.7215\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 866s 1ms/step - loss: 0.5658 - acc: 0.6818 - val_loss: 0.6012 - val_acc: 0.7176\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 861s 1ms/step - loss: 0.5584 - acc: 0.6922 - val_loss: 0.6188 - val_acc: 0.6726\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 864s 1ms/step - loss: 0.5523 - acc: 0.7001 - val_loss: 0.6388 - val_acc: 0.6457\n",
      "Epoch 00005: early stopping\n",
      "Fitting the  28 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 859s 1ms/step - loss: 0.6133 - acc: 0.6479 - val_loss: 0.6483 - val_acc: 0.6479\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 859s 1ms/step - loss: 0.5760 - acc: 0.6668 - val_loss: 0.6411 - val_acc: 0.6474\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 856s 1ms/step - loss: 0.5655 - acc: 0.6817 - val_loss: 0.5892 - val_acc: 0.7344\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 858s 1ms/step - loss: 0.5574 - acc: 0.6935 - val_loss: 0.6259 - val_acc: 0.6685\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 851s 1ms/step - loss: 0.5508 - acc: 0.7018 - val_loss: 0.6207 - val_acc: 0.6745\n",
      "Fitting the  29 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 859s 1ms/step - loss: 0.6106 - acc: 0.6488 - val_loss: 0.6355 - val_acc: 0.6530\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5747 - acc: 0.6692 - val_loss: 0.6432 - val_acc: 0.6479\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 859s 1ms/step - loss: 0.5643 - acc: 0.6853 - val_loss: 0.6185 - val_acc: 0.6903\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 855s 1ms/step - loss: 0.5572 - acc: 0.6958 - val_loss: 0.6431 - val_acc: 0.6370\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.5505 - acc: 0.7030 - val_loss: 0.6247 - val_acc: 0.6637\n",
      "Fitting the  30 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 864s 1ms/step - loss: 0.6074 - acc: 0.6495 - val_loss: 0.6312 - val_acc: 0.6535\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 929s 1ms/step - loss: 0.5742 - acc: 0.6695 - val_loss: 0.6349 - val_acc: 0.6474\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 964s 1ms/step - loss: 0.5638 - acc: 0.6853 - val_loss: 0.6201 - val_acc: 0.6921\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 945s 1ms/step - loss: 0.5556 - acc: 0.6978 - val_loss: 0.6250 - val_acc: 0.6800\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 956s 1ms/step - loss: 0.5496 - acc: 0.7068 - val_loss: 0.5941 - val_acc: 0.7279\n",
      "Fitting the  31 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 945s 1ms/step - loss: 0.6087 - acc: 0.6494 - val_loss: 0.6482 - val_acc: 0.6283\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 968s 1ms/step - loss: 0.5733 - acc: 0.6692 - val_loss: 0.6083 - val_acc: 0.7123\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 990s 1ms/step - loss: 0.5623 - acc: 0.6863 - val_loss: 0.6479 - val_acc: 0.6333\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 981s 1ms/step - loss: 0.5538 - acc: 0.6981 - val_loss: 0.6419 - val_acc: 0.6637\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 973s 1ms/step - loss: 0.5484 - acc: 0.7066 - val_loss: 0.6150 - val_acc: 0.6813\n",
      "Epoch 00005: early stopping\n",
      "Fitting the  32 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1022s 1ms/step - loss: 0.6091 - acc: 0.6461 - val_loss: 0.6371 - val_acc: 0.6414\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 970s 1ms/step - loss: 0.5734 - acc: 0.6699 - val_loss: 0.6427 - val_acc: 0.6498\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 967s 1ms/step - loss: 0.5631 - acc: 0.6851 - val_loss: 0.6212 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 959s 1ms/step - loss: 0.5561 - acc: 0.6965 - val_loss: 0.6249 - val_acc: 0.6800\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 1046s 1ms/step - loss: 0.5493 - acc: 0.7047 - val_loss: 0.6288 - val_acc: 0.6743\n",
      "Fitting the  33 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1002s 1ms/step - loss: 0.6995 - acc: 0.5929 - val_loss: 0.6702 - val_acc: 0.6163\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1013s 1ms/step - loss: 0.6486 - acc: 0.6095 - val_loss: 0.6591 - val_acc: 0.6351\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 1001s 1ms/step - loss: 0.6310 - acc: 0.6318 - val_loss: 0.6580 - val_acc: 0.6267\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 999s 1ms/step - loss: 0.6255 - acc: 0.6463 - val_loss: 0.6519 - val_acc: 0.6340\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 996s 1ms/step - loss: 0.6237 - acc: 0.6538 - val_loss: 0.6602 - val_acc: 0.6102\n",
      "Fitting the  34 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1083s 2ms/step - loss: 0.6990 - acc: 0.5880 - val_loss: 0.6883 - val_acc: 0.5878\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1412s 2ms/step - loss: 0.6508 - acc: 0.6063 - val_loss: 0.6835 - val_acc: 0.5688\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 998s 1ms/step - loss: 0.6462 - acc: 0.6109 - val_loss: 0.6709 - val_acc: 0.6450\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 993s 1ms/step - loss: 0.6458 - acc: 0.6141 - val_loss: 0.6904 - val_acc: 0.5740\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 999s 1ms/step - loss: 0.6455 - acc: 0.6176 - val_loss: 0.6737 - val_acc: 0.6080\n",
      "Fitting the  35 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 1013s 1ms/step - loss: 0.6911 - acc: 0.5961 - val_loss: 0.6707 - val_acc: 0.6303\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 997s 1ms/step - loss: 0.6322 - acc: 0.6276 - val_loss: 0.6702 - val_acc: 0.5744\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 974s 1ms/step - loss: 0.6269 - acc: 0.6380 - val_loss: 0.6639 - val_acc: 0.5976\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 1010s 1ms/step - loss: 0.6256 - acc: 0.6468 - val_loss: 0.6435 - val_acc: 0.6569\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 857s 1ms/step - loss: 0.6242 - acc: 0.6503 - val_loss: 0.6521 - val_acc: 0.6140\n",
      "Fitting the  36 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 871s 1ms/step - loss: 0.6828 - acc: 0.6006 - val_loss: 0.6686 - val_acc: 0.6026\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 850s 1ms/step - loss: 0.6303 - acc: 0.6277 - val_loss: 0.6602 - val_acc: 0.6189\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 845s 1ms/step - loss: 0.6270 - acc: 0.6418 - val_loss: 0.6690 - val_acc: 0.5801\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 906s 1ms/step - loss: 0.6250 - acc: 0.6460 - val_loss: 0.6497 - val_acc: 0.6544\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 992s 1ms/step - loss: 0.6249 - acc: 0.6497 - val_loss: 0.6616 - val_acc: 0.6118\n",
      "Fitting the  37 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 955s 1ms/step - loss: 0.6872 - acc: 0.5940 - val_loss: 0.6961 - val_acc: 0.5720\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 982s 1ms/step - loss: 0.6482 - acc: 0.6052 - val_loss: 0.6568 - val_acc: 0.6624\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 975s 1ms/step - loss: 0.6437 - acc: 0.6123 - val_loss: 0.6706 - val_acc: 0.6252\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 977s 1ms/step - loss: 0.6324 - acc: 0.6284 - val_loss: 0.6571 - val_acc: 0.6260\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 975s 1ms/step - loss: 0.6249 - acc: 0.6439 - val_loss: 0.6343 - val_acc: 0.6769\n",
      "Fitting the  38 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 970s 1ms/step - loss: 0.6924 - acc: 0.5784 - val_loss: 0.6777 - val_acc: 0.6035\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 971s 1ms/step - loss: 0.6508 - acc: 0.6003 - val_loss: 0.6879 - val_acc: 0.5551\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 968s 1ms/step - loss: 0.6480 - acc: 0.6089 - val_loss: 0.6782 - val_acc: 0.5683\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 881s 1ms/step - loss: 0.6461 - acc: 0.6110 - val_loss: 0.6841 - val_acc: 0.5694\n",
      "Epoch 00004: early stopping\n",
      "Fitting the  39 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 873s 1ms/step - loss: 0.6824 - acc: 0.5911 - val_loss: 0.6637 - val_acc: 0.6434\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 870s 1ms/step - loss: 0.6365 - acc: 0.6173 - val_loss: 0.6727 - val_acc: 0.5646\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 863s 1ms/step - loss: 0.6260 - acc: 0.6360 - val_loss: 0.6457 - val_acc: 0.6401\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 874s 1ms/step - loss: 0.6223 - acc: 0.6436 - val_loss: 0.6543 - val_acc: 0.6091\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 863s 1ms/step - loss: 0.6213 - acc: 0.6498 - val_loss: 0.6751 - val_acc: 0.5709\n",
      "Fitting the  40 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 975s 1ms/step - loss: 0.6741 - acc: 0.6026 - val_loss: 0.6570 - val_acc: 0.6149\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 1048s 1ms/step - loss: 0.6278 - acc: 0.6316 - val_loss: 0.6606 - val_acc: 0.5999\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 1028s 1ms/step - loss: 0.6240 - acc: 0.6412 - val_loss: 0.6674 - val_acc: 0.6435\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 989s 1ms/step - loss: 0.6217 - acc: 0.6482 - val_loss: 0.6461 - val_acc: 0.6554\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 983s 1ms/step - loss: 0.6202 - acc: 0.6550 - val_loss: 0.6632 - val_acc: 0.6104\n",
      "Fitting the  41 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 974s 1ms/step - loss: 0.6658 - acc: 0.6040 - val_loss: 0.6734 - val_acc: 0.5944\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 978s 1ms/step - loss: 0.6262 - acc: 0.6355 - val_loss: 0.6586 - val_acc: 0.6125\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 958s 1ms/step - loss: 0.6216 - acc: 0.6450 - val_loss: 0.6557 - val_acc: 0.6385\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 869s 1ms/step - loss: 0.6197 - acc: 0.6511 - val_loss: 0.6551 - val_acc: 0.6361\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 862s 1ms/step - loss: 0.6184 - acc: 0.6551 - val_loss: 0.6550 - val_acc: 0.6323\n",
      "Fitting the  42 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 872s 1ms/step - loss: 0.6742 - acc: 0.5939 - val_loss: 0.6575 - val_acc: 0.6375\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 870s 1ms/step - loss: 0.6303 - acc: 0.6338 - val_loss: 0.6584 - val_acc: 0.6108\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 871s 1ms/step - loss: 0.6258 - acc: 0.6408 - val_loss: 0.6481 - val_acc: 0.6319\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 869s 1ms/step - loss: 0.6233 - acc: 0.6457 - val_loss: 0.6431 - val_acc: 0.6679\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 863s 1ms/step - loss: 0.6228 - acc: 0.6508 - val_loss: 0.6553 - val_acc: 0.6180\n",
      "Fitting the  43 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 870s 1ms/step - loss: 0.6667 - acc: 0.6025 - val_loss: 0.6600 - val_acc: 0.6164\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702308/702308 [==============================] - 877s 1ms/step - loss: 0.6271 - acc: 0.6343 - val_loss: 0.6584 - val_acc: 0.6276\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 865s 1ms/step - loss: 0.6242 - acc: 0.6415 - val_loss: 0.6553 - val_acc: 0.6312\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 866s 1ms/step - loss: 0.6221 - acc: 0.6492 - val_loss: 0.6533 - val_acc: 0.6358\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 873s 1ms/step - loss: 0.6201 - acc: 0.6534 - val_loss: 0.6512 - val_acc: 0.6337\n",
      "Fitting the  44 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 874s 1ms/step - loss: 0.6781 - acc: 0.5837 - val_loss: 0.6647 - val_acc: 0.6210\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 871s 1ms/step - loss: 0.6354 - acc: 0.6127 - val_loss: 0.6247 - val_acc: 0.6814\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 864s 1ms/step - loss: 0.6270 - acc: 0.6300 - val_loss: 0.6675 - val_acc: 0.5762\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 869s 1ms/step - loss: 0.6239 - acc: 0.6384 - val_loss: 0.6536 - val_acc: 0.6228\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 866s 1ms/step - loss: 0.6223 - acc: 0.6460 - val_loss: 0.6689 - val_acc: 0.6012\n",
      "Epoch 00005: early stopping\n",
      "Fitting the  45 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 867s 1ms/step - loss: 0.6751 - acc: 0.5922 - val_loss: 0.6602 - val_acc: 0.6350\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 876s 1ms/step - loss: 0.6305 - acc: 0.6247 - val_loss: 0.6446 - val_acc: 0.6583\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 872s 1ms/step - loss: 0.6229 - acc: 0.6394 - val_loss: 0.6627 - val_acc: 0.6049\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 868s 1ms/step - loss: 0.6212 - acc: 0.6448 - val_loss: 0.6466 - val_acc: 0.6425\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 882s 1ms/step - loss: 0.6199 - acc: 0.6492 - val_loss: 0.6505 - val_acc: 0.6227\n",
      "Epoch 00005: early stopping\n",
      "Fitting the  46 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 866s 1ms/step - loss: 0.6618 - acc: 0.6062 - val_loss: 0.6599 - val_acc: 0.5896\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 866s 1ms/step - loss: 0.6264 - acc: 0.6289 - val_loss: 0.6485 - val_acc: 0.6280\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 863s 1ms/step - loss: 0.6218 - acc: 0.6406 - val_loss: 0.6402 - val_acc: 0.6502\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 872s 1ms/step - loss: 0.6191 - acc: 0.6485 - val_loss: 0.6477 - val_acc: 0.6434\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 862s 1ms/step - loss: 0.6172 - acc: 0.6495 - val_loss: 0.6405 - val_acc: 0.6870\n",
      "Fitting the  47 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 869s 1ms/step - loss: 0.6596 - acc: 0.6058 - val_loss: 0.6568 - val_acc: 0.6091\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 867s 1ms/step - loss: 0.6262 - acc: 0.6327 - val_loss: 0.6649 - val_acc: 0.5794\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 869s 1ms/step - loss: 0.6210 - acc: 0.6417 - val_loss: 0.6304 - val_acc: 0.6701\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 869s 1ms/step - loss: 0.6190 - acc: 0.6474 - val_loss: 0.6342 - val_acc: 0.6742\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 876s 1ms/step - loss: 0.6182 - acc: 0.6488 - val_loss: 0.6492 - val_acc: 0.6438\n",
      "Fitting the  48 / 48  model\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/5\n",
      "702308/702308 [==============================] - 870s 1ms/step - loss: 0.6578 - acc: 0.6089 - val_loss: 0.6598 - val_acc: 0.5977\n",
      "Epoch 2/5\n",
      "702308/702308 [==============================] - 882s 1ms/step - loss: 0.6235 - acc: 0.6364 - val_loss: 0.6526 - val_acc: 0.6312\n",
      "Epoch 3/5\n",
      "702308/702308 [==============================] - 880s 1ms/step - loss: 0.6200 - acc: 0.6448 - val_loss: 0.6330 - val_acc: 0.6768\n",
      "Epoch 4/5\n",
      "702308/702308 [==============================] - 972s 1ms/step - loss: 0.6186 - acc: 0.6542 - val_loss: 0.6445 - val_acc: 0.6283\n",
      "Epoch 5/5\n",
      "702308/702308 [==============================] - 1178s 2ms/step - loss: 0.6166 - acc: 0.6541 - val_loss: 0.6387 - val_acc: 0.6619\n",
      "0.7102173089773272\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Define the drop out grid\n",
    "dropout_grid = [0.1, 0.5, 0.9]\n",
    "l1_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "l2_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "tot = len(dropout_grid) * len(l1_grid) * len(l2_grid)\n",
    "\n",
    "# Variables for the best result\n",
    "best_history = [] # place holder\n",
    "best_ind = 0\n",
    "best_acc = 0\n",
    "\n",
    "# Loop through each combination\n",
    "pos = 0\n",
    "for ii in dropout_grid:\n",
    "    for jj in l1_grid:\n",
    "        for kk in l2_grid:\n",
    "            pos = pos + 1\n",
    "            print(\"Fitting the \", pos, \"/\", tot , \" model\")\n",
    "            # define the model\n",
    "            curr_model = define_cnn_model(ii, jj, kk)\n",
    "            \n",
    "            # train the model\n",
    "            curr_history = curr_model.fit(X_train_seq, y_train_encoded, epochs = 5, class_weight = label_weights,\n",
    "                                          batch_size = 64, validation_data = (X_test_seq, y_test_encoded), \n",
    "                                          callbacks = [callback], verbose = 1)\n",
    "            curr_acc = st.mean(curr_history.history['val_acc'])\n",
    "            \n",
    "            # save the best result\n",
    "            if best_acc < curr_acc:\n",
    "                best_acc = curr_acc\n",
    "                best_ind = pos - 1\n",
    "                best_history = curr_history\n",
    "                \n",
    "print(best_acc)\n",
    "print(best_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_53 (Embedding)     (None, 1000, 10)          10000     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 998, 16)           496       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 499, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 497, 16)           784       \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 7952)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 250)               1988250   \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 2,000,283\n",
      "Trainable params: 2,000,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 702308 samples, validate on 345913 samples\n",
      "Epoch 1/15\n",
      " 21824/702308 [..............................] - ETA: 19:50 - loss: 0.7749 - acc: 0.5746 ETA: 19:48 "
     ]
    }
   ],
   "source": [
    "model = define_cnn_model(0.5)\n",
    "model.summary()\n",
    "history = model.fit(X_train_seq, y_train_encoded, epochs = 15, class_weight = label_weights, batch_size = 64, \n",
    "                    validation_data = (X_test_seq, y_test_encoded), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-scheme",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
